{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c46e417d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./langgraph/lib/python3.10/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-openai in ./langgraph/lib/python3.10/site-packages (0.3.32)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: langgraph in ./langgraph/lib/python3.10/site-packages (0.6.6)\n",
      "Requirement already satisfied: python-dotenv in ./langgraph/lib/python3.10/site-packages (1.1.1)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.13.0-cp39-abi3-macosx_14_0_arm64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting pypdf\n",
      "  Downloading pypdf-6.4.0-py3-none-any.whl (329 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.5/329.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./langgraph/lib/python3.10/site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in ./langgraph/lib/python3.10/site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in ./langgraph/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in ./langgraph/lib/python3.10/site-packages (from langchain) (0.4.25)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in ./langgraph/lib/python3.10/site-packages (from langchain) (0.3.75)\n",
      "Requirement already satisfied: requests<3,>=2 in ./langgraph/lib/python3.10/site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./langgraph/lib/python3.10/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./langgraph/lib/python3.10/site-packages (from langchain) (2.0.43)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./langgraph/lib/python3.10/site-packages (from langchain-openai) (0.11.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.99.9 in ./langgraph/lib/python3.10/site-packages (from langchain-openai) (1.106.1)\n",
      "Collecting langchain-classic<2.0.0,>=1.0.0\n",
      "  Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting dataclasses-json<0.7.0,>=0.6.7\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1\n",
      "  Downloading pydantic_settings-2.12.0-py3-none-any.whl (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain-community\n",
      "  Downloading langchain_community-0.4-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading langchain_community-0.3.31-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting httpx-sse<1.0.0,>=0.4.0\n",
      "  Downloading httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Downloading aiohttp-3.13.2-cp310-cp310-macosx_11_0_arm64.whl (489 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.3/489.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.26.2\n",
      "  Using cached numpy-2.2.6-cp310-cp310-macosx_14_0_arm64.whl (5.3 MB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./langgraph/lib/python3.10/site-packages (from langchain-community) (9.1.2)\n",
      "Collecting langchain-core<1.0.0,>=0.3.72\n",
      "  Downloading langchain_core-0.3.80-py3-none-any.whl (450 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.8/450.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in ./langgraph/lib/python3.10/site-packages (from langgraph) (2.1.1)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in ./langgraph/lib/python3.10/site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in ./langgraph/lib/python3.10/site-packages (from langgraph) (0.2.6)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in ./langgraph/lib/python3.10/site-packages (from langgraph) (0.6.4)\n",
      "Requirement already satisfied: packaging in ./langgraph/lib/python3.10/site-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in ./langgraph/lib/python3.10/site-packages (from pypdf) (4.15.0)\n",
      "Collecting propcache>=0.2.0\n",
      "  Downloading propcache-0.4.1-cp310-cp310-macosx_11_0_arm64.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal>=1.4.0\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./langgraph/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.8.0-cp310-cp310-macosx_11_0_arm64.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 kB\u001b[0m \u001b[31m970.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting aiohappyeyeballs>=2.5.0\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.7.0-cp310-cp310-macosx_11_0_arm64.whl (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.17.0\n",
      "  Downloading yarl-1.22.0-cp310-cp310-macosx_11_0_arm64.whl (94 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.4/94.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting marshmallow<4.0.0,>=3.18.0\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-inspect<1,>=0.4.0\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./langgraph/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in ./langgraph/lib/python3.10/site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in ./langgraph/lib/python3.10/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
      "Requirement already satisfied: httpx>=0.25.2 in ./langgraph/lib/python3.10/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./langgraph/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./langgraph/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
      "Requirement already satisfied: sniffio in ./langgraph/lib/python3.10/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./langgraph/lib/python3.10/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./langgraph/lib/python3.10/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: tqdm>4 in ./langgraph/lib/python3.10/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./langgraph/lib/python3.10/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (4.10.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./langgraph/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./langgraph/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./langgraph/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./langgraph/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./langgraph/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./langgraph/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./langgraph/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./langgraph/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2025.9.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./langgraph/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.99.9->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./langgraph/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./langgraph/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./langgraph/lib/python3.10/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: pypdf, propcache, numpy, mypy-extensions, multidict, marshmallow, httpx-sse, frozenlist, aiohappyeyeballs, yarl, typing-inspect, faiss-cpu, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langchain-core, langchain-community\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.75\n",
      "    Uninstalling langchain-core-0.3.75:\n",
      "      Successfully uninstalled langchain-core-0.3.75\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 dataclasses-json-0.6.7 faiss-cpu-1.13.0 frozenlist-1.8.0 httpx-sse-0.4.3 langchain-community-0.3.31 langchain-core-0.3.80 marshmallow-3.26.1 multidict-6.7.0 mypy-extensions-1.1.0 numpy-2.2.6 propcache-0.4.1 pydantic-settings-2.12.0 pypdf-6.4.0 typing-inspect-0.9.0 yarl-1.22.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain langchain-openai langchain-community langgraph python-dotenv faiss-cpu pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1701a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, START\n",
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, BaseMessage\n",
    "from langgraph.prebuilt import ToolNode, tools_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e4b28b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e967fa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "727373a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"intro-to-ml.pdf\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d023e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf119ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c7079f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "973"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f56d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "vector_store = FAISS.from_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaa9052",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497ab409",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def rag_tool(query):\n",
    "\n",
    "    \"\"\"\n",
    "    Retrieve relevant information from the pdf document.\n",
    "    Use this tool when the user asks factual / conceptual questions\n",
    "    that might be answered from the stored documents.\n",
    "    \"\"\"\n",
    "    result = retriever.invoke(query)\n",
    "\n",
    "    context = [doc.page_content for doc in result]\n",
    "    metadata = [doc.metadata for doc in result]\n",
    "\n",
    "    return {\n",
    "        'query': query,\n",
    "        'context': context,\n",
    "        'metadata': metadata\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87763b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [rag_tool]\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae0f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba00b5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_node(state: ChatState):\n",
    "\n",
    "    messages = state['messages']\n",
    "\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "\n",
    "    return {'messages': [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884ae5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85470f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(ChatState)\n",
    "\n",
    "graph.add_node('chat_node', chat_node)\n",
    "graph.add_node('tools', tool_node)\n",
    "\n",
    "graph.add_edge(START, 'chat_node')\n",
    "graph.add_conditional_edges('chat_node', tools_condition)\n",
    "graph.add_edge('tools', 'chat_node')\n",
    "\n",
    "chatbot = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cdf89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e49c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chatbot.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=(\n",
    "                    \"Using the pdf notes, explain how to find the ideal value of K in KNN\"\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d37c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87ca56b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
